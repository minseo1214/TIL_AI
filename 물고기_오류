from sklearn.neighbors import KNeighborsClassifier
import numpy as np
import matplotlib.pyplot as plt #mathplotlub의 pylot함수를 plt로 줄여서 사용.테스

smelt_length=[9.8,10.5,10.6,11.0,11.2,11.3,11.8,11.8,12.0,12.2,12.4,13.0,14.3,15.0]
smelt_weight=[6.7,7.5,7.0,9.7,9.8,8.7,10.0,9.9,9.8,12.2,13.4,12.2,19.7,19.9]


bream_length=[25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0,41.0]
bream_weight=[242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0,920.0]

lenght=bream_length+smelt_length
weight=bream_weight+smelt_weight
fish_target=[1]*35+[0]*14
fish_data=[[l,w]for l,w in zip(lenght,weight)]
kn=KNeighborsClassifier()
print(fish_data[4])
print(fish_data[:5])
train_input = fish_data[:35]
train_target=fish_target[:35]
test_input=fish_data[35:]
test_target=fish_target[35:]
kn=kn.fit(train_input,train_target)
kn.score(test_input,test_target)

#이렇게 하면 정확도가 0.0이 나오게 되는데 이 이유는 훈련세트는 0~35(도미)였는데 테스트세트는36~49(빙어)이기 때문에 정확도가 맞지 않게 된다.
#이렇게 훈련세트와 테스트세트에 샘플이 골고루 섞어있지 않으면 샘플링이 편향되어있다는 뜻으로 sampling bias(샘플링 편향)이라고 부릅니다
