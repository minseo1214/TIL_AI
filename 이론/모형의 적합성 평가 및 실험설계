모형의 적합성 평가 및 실험설계
- 모형의 적합성을 평가하는 방법
 - 학습집합의 MSE는 복잡한 모형일 수록 감소하지만, 학습 데이터가 아닌 또 다른 데이터(검증 데이터)의 MSE는 일정 시점이후로 증가
 - 증가하는 원인은 모형이 학습 집합에 과적합되기때문
모델이 복잡할 수록 학습데이터는 잘 맞고 테스트데이터에 안맞는다
간단한 모델은 underfitting되었다고 볼 수 있다.

데이터 분할
original dataset
training&test -> 8:2,7:3
training&validation&test -> 5:3:2
과적합을 방지하기 위해 전체 데이터를 학습 데이터, 검증 데이터, 테스트 데이터로 나누며 보통 비율은 5:3:2로 정함.

학습데이터(training data) : 모형 f를 추정하는데 필요
검증 데이터(validation data) : 추정한 모형 f가 적합한지 검증함
테스트 데이터(test data) : 최종적으로 선택한 모형의 성능평가

쉽게 말하면 학습시킬 때 잘 학습되고 있는지 확인할 때 쓰는 데이터가 validation data이고 최종적으로 학습이 다 되었을 때 test data를 모델에 넣어 확인한다.
overfitting을 막기위해 학습데이터와 다른데이터로 확인해야 하는데 최적화 할 때 확인용 데이터 정보가 모델에 들어가 학습되기 때문에
그것을 test data에 넣어서 쓰면 올바른 test가 이루어지지 않기 때문에 따로 학습 중에 학습이 잘 되고 있는지 확인 할 수 있도록 따로 분류해 놓는다.
이때 이 데이터를 검증용 데이터라고 한다.


k-Fold 교차검증(k-Fold Cross Validation)
 -모형의 적합성을 보다 객관적으로 평가하기 위한 방법
 - 데이터를 k(주로 5 또는 10)개 부분으로 나눈 뒤, 그 중 하나를 검증 집합, 나머지를 학습집합으로 분류
 - 위 과정을 k번 반복하고 k개의 성능 지표를 평균하여 모형의 적합성 평가
 
LOOCV(Leave-One-Out Cross Validation)
  - 데이터의 수가 적을 때 사용하는 교차검증 방법
  - 총 n(데이터 수 만큼)개의 모델을 만드는데, 각 모델은 하나의 샘플만 제외하면서 모델은 만들고 제외한 샘플로 성능 지표를 계산함.
  이렇게 도출된 n개의 성능 지표를 평균내어 최종 성능 지표를 도출
  
