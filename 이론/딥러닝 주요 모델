기본지식!
 독립변수
   직접 변경하는 변수-> X
 종속변수
   독립변수에 따라 변화하는 변수 -> Y

Neural Network
  - 입력, 은닉, 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트하면서 학습
  - Overfitting이 심하게 일어나고 학습시간이 매우 오래걸림

Deep Learning
  - 다층의 layer를 통해 복잡한 데이터의 학습이 가능하도록 함(graphical representation learning)
  - 알고리즘 및 GPU의 발전이 deep learning의 부흥을 이끔
  
  이미지 처리에 사용되는 CNN(Concolutional Neural Network)
  
기존에 머신러닝으로도 이미지 분류가 가능했지만, 각각의 독립변수가 독립적이지 않다는 문제점이 있었음.
CNN은 feature을 뽑아내서 다시 하나의 백터로 만들어 딥러닝을 시킨다.

다양한 형태 : CNN,RNN,AutoEncoder
다양한 분야 : Object detection(분류), Image Resolution(해상도 복원),style transfer,colorzation(색 입히기)
네트워크 구조의 발전(ResNet,DenseNet)
네트워크 초기화 기법(Xavier,he initalization 등)
다양한 activation function(ReLu,ELU,SeLU,Leaky ReLU 등)
Generalization,overfitting에 관한 문제
Semi-supervised learning,Unsupervised learning

GAN(Generative Adversarial Network)
Data를 만들어내는 Generator와 만들어진 data를 평가하는 Discriminator가 서로 대립(Adversarial)적으로 학습해가며
성능을 점차 개선해 나가자는 개념
생성하는게 주 목적!
-Discriminator를 학습시킬 때에서는 D(x)가 1이되고 D(G(z))가 0이되도록 학습시킴.
(진짜 데이터를 진짜로 판별하고, 가짜데이터를 가짜로 판별 할 수 있도록
D(x)에서 x는 real data, D(G(z))에서 z는 노이즈 데이터 G(z)->fake

-Generator를 학습시킬 때에서는 D(G(z))가 1이되도록 학습시킴.
(가짜데이터를 discriminator가 구분못하도록 학습,discriminator를 헷갈리게 하도록)
