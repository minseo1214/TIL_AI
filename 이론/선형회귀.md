#선형회귀
예측을 위해 사용하는 데이터를 훈련데이터라고한다.
훈련 후 모델이 잘 학습했는지 확인하기 위해 사용하는 데이터를 테스트데이터셋이라고한다.


##비용함수
예를 들어 4개의 점에 가장 잘 표현하는 선을 그으려고 할 때, 점과 선 사이의 오차를 계산해주는 것이 비용함수라고한다.
<img width="414" alt="image" src="https://user-images.githubusercontent.com/68543486/133252442-dcbecf2d-fca7-4826-9015-21a5187d59bf.png">
이때
<img width="87" alt="image" src="https://user-images.githubusercontent.com/68543486/133253098-85eca31b-4913-40b9-aea4-889e09124d3b.png">
이러한 식이 사용되는데 여기서 w는 가중치, b는 바이어스라고한다.

##옵티마이저
이제 비용함수의 값을 최소로하는 W값을 정해야하는데 이때 사용하는 것이 옵티마이저알고리즘이다. 최적화 알고리즘이라고도한다.
아까 비용함수에서 오차율은 제곱으로인해 양수만 나오게되는데, 그것을 그래프로 나타내며 아래 그래프가 된다.
<img width="306" alt="image" src="https://user-images.githubusercontent.com/68543486/133253368-e7a3ef4b-8179-47e3-be3a-ff04ba94cd22.png">
여기에서 오차율이 최솟값이 되기위해서느 순간변화율, 즉 접선의 기울기가 0과 가까워져야합니다.

이때 임의의 a값을 설정하여 다음과 같은 식에 대입하는데 다음 식으 참고하자.
<img width="730" alt="image" src="https://user-images.githubusercontent.com/68543486/133253770-68ad8408-9822-4a96-926d-e6d150a5bd7d.png">
이 a의 값이 지나치게 크게되면 아래와 같은 현상이 일어나므로 조심하자.
<img width="298" alt="image" src="https://user-images.githubusercontent.com/68543486/133254356-6c3dd777-6cb4-45ef-b4ec-cfd715c95e7b.png">
